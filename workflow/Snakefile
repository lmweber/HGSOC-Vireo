#####################################
# Snakefile to run Snakemake workflow
#####################################

# ---------
# variables
# ---------

dir_scripts = "scripts"
dir_data = "../../data"
dir_data_cellranger_ref = dir_data + "/cellranger/refdata-gex-GRCh38-2020-A"
dir_outputs = "../../workflow/outputs"
dir_outputs_HGSOC = dir_outputs + "/HGSOC"
dir_runtimes = "../../workflow/runtimes"
dir_runtimes_HGSOC = dir_runtimes + "/HGSOC"
dir_timestamps = "../../workflow/timestamps"
dir_timestamps_HGSOC = dir_timestamps + "/HGSOC"


sample_ids_HGSOC = ["16030X2_HJVMLDMXX", "16030X3_HJTWLDMXX", "16030X4_HJTWLDMXX"]
sample_ids_HGSOC_short = ["X2", "X3", "X4"]
sample_ids_HGSOC_short_named = {"16030X2_HJVMLDMXX": "X2", 
                                "16030X3_HJTWLDMXX": "X3", 
                                "16030X4_HJTWLDMXX": "X4"}

fastq_dirs_HGSOC = {"16030X2_HJVMLDMXX": "../../data/HGSOC/16030R/Fastq/16030X2_HJVMLDMXX", 
                    "16030X3_HJTWLDMXX": "../../data/HGSOC/16030R/Fastq/16030X3_HJTWLDMXX", 
                    "16030X4_HJTWLDMXX": "../../data/HGSOC/16030R/Fastq/16030X4_HJTWLDMXX"}


# ------------
# run workflow
# ------------

# command to run workflow on cluster
# notes:
# - using number of threads specified in each rule
# - using memory equal to "threads * mem_free" and "threads * h_vmem" (if more 
# precise control is required over the amount of memory for each job, this could 
# be specified in a Snakemake cluster config file)

# snakemake --cluster "qsub -V -cwd -pe local {threads} -l mem_free=5G,h_vmem=10G,h_fsize=100G" -j 3 --local-cores 30 --latency-wait 10


# --------------
# workflow rules
# --------------

# default rule

rule all:
  input:
    dir_timestamps_HGSOC + "/vireo/timestamp_vireo.txt"


# ---------
# run Vireo
# ---------

# HGSOC (3 samples)
rule run_vireo_HGSOC:
  input:
    dir_timestamps_HGSOC + "/cellSNP/timestamp_cellSNP.txt", 
    script_vireo = dir_scripts + "/run_vireo.sh"
  output:
    dir_timestamps_HGSOC + "/vireo/timestamp_vireo.txt"
  params:
    n_samples = 3
  threads: 1
  shell:
    "bash {input.script_vireo} {dir_runtimes_HGSOC} {dir_timestamps_HGSOC} {threads} "
    "{dir_outputs_HGSOC} {params.n_samples}"


# -----------
# run cellSNP
# -----------

# HGSOC
rule run_cellSNP_HGSOC:
  input:
    dir_timestamps_HGSOC + "/parse_and_merge_barcodes/timestamp_parse_and_merge_barcodes.txt", 
    script_cellSNP = dir_scripts + "/run_cellSNP.sh"
  output:
    dir_timestamps_HGSOC + "/cellSNP/timestamp_cellSNP.txt"
  threads: 10
  shell:
    "bash {input.script_cellSNP} {dir_runtimes_HGSOC} {dir_timestamps_HGSOC} {threads} "
    "{dir_data} {dir_outputs_HGSOC}"


# ----------------------------------
# parse and merge cell barcode files
# ----------------------------------

# HGSOC
rule parse_and_merge_barcodes_HGSOC:
  input:
    dir_timestamps_HGSOC + "/merge_and_index_BAM/timestamp_merge_and_index_BAM.txt", 
    script_parse_and_merge_barcodes = dir_scripts + "/parse_and_merge_barcodes_HGSOC.sh"
  output:
    dir_timestamps_HGSOC + "/parse_and_merge_barcodes/timestamp_parse_and_merge_barcodes.txt"
  params:
    sample_id_1 = lambda wildcards: sample_ids_HGSOC[0], 
    sample_id_2 = lambda wildcards: sample_ids_HGSOC[1], 
    sample_id_3 = lambda wildcards: sample_ids_HGSOC[2], 
    sample_id_1_short = lambda wildcards: sample_ids_HGSOC_short[0], 
    sample_id_2_short = lambda wildcards: sample_ids_HGSOC_short[1], 
    sample_id_3_short = lambda wildcards: sample_ids_HGSOC_short[2]
  threads: 1
  shell:
    "bash {input.script_parse_and_merge_barcodes} {dir_runtimes_HGSOC} {dir_timestamps_HGSOC} {threads} "
    "{dir_outputs_HGSOC} "
    "{params.sample_id_1} {params.sample_id_2} {params.sample_id_3} "
    "{params.sample_id_1_short} {params.sample_id_2_short} {params.sample_id_3_short}"


# -------------------------
# merge and index BAM files
# -------------------------

# HGSOC
rule merge_and_index_BAM_HGSOC:
  input:
    expand(dir_timestamps_HGSOC + "/parse_BAM_files/timestamp_parse_BAM_files_{sample_HGSOC}.txt", sample_HGSOC = sample_ids_HGSOC), 
    script_merge_and_index_BAM = dir_scripts + "/merge_and_index_BAM_HGSOC.sh"
  output:
    dir_timestamps_HGSOC + "/merge_and_index_BAM/timestamp_merge_and_index_BAM.txt"
  params:
    sample_id_1 = lambda wildcards: sample_ids_HGSOC[0], 
    sample_id_2 = lambda wildcards: sample_ids_HGSOC[1], 
    sample_id_3 = lambda wildcards: sample_ids_HGSOC[2]
  threads: 1
  shell:
    "bash {input.script_merge_and_index_BAM} {dir_runtimes_HGSOC} {dir_timestamps_HGSOC} {threads} "
    "{dir_outputs_HGSOC} {params.sample_id_1} {params.sample_id_2} {params.sample_id_3}"


# ---------------------------------------------------------
# parse BAM files to add unique sample IDs to cell barcodes
# ---------------------------------------------------------

# HGSOC
rule parse_BAM_files_HGSOC:
  input:
    dir_timestamps_HGSOC + "/cellranger/timestamp_cellranger_{sample_HGSOC}.txt", 
    script_parse_BAM_files = dir_scripts + "/parse_BAM_files.sh"
  output:
    dir_timestamps_HGSOC + "/parse_BAM_files/timestamp_parse_BAM_files_{sample_HGSOC}.txt"
  params:
    short_sample_id = lambda wildcards: sample_ids_HGSOC_short_named[wildcards.sample_HGSOC]
  threads: 1
  shell:
    "bash {input.script_parse_BAM_files} {dir_runtimes_HGSOC} {dir_timestamps_HGSOC} {threads} "
    "{wildcards.sample_HGSOC} {params.short_sample_id} {dir_outputs_HGSOC}"


# ---------------
# run Cell Ranger
# ---------------

# HGSOC
rule run_cellranger_HGSOC:
  input:
    script_cellranger = dir_scripts + "/run_cellranger.sh"
  output:
    dir_timestamps_HGSOC + "/cellranger/timestamp_cellranger_{sample_HGSOC}.txt"
  params:
    fastq_dir = lambda wildcards: fastq_dirs_HGSOC[wildcards.sample_HGSOC]
  threads: 10
  shell:
    "bash {input.script_cellranger} {dir_runtimes_HGSOC} {dir_timestamps_HGSOC} {threads} "
    "{wildcards.sample_HGSOC} {dir_data_cellranger_ref} "
    "{params.fastq_dir} {dir_outputs_HGSOC}"

