#####################################
# Snakefile to run Snakemake workflow
#####################################

# This Snakefile runs a complete workflow for one dataset, doublets simulation 
# scenario, and choice of genotype file. This can be extended to include additional 
# simulation scenarios by modifying the rules below, or adding separate scripts. 
# For examples of scripts for additional scenarios, see the scripts saved in the 
# "benchmarking/run_scenarios" directory.


# ---------
# variables
# ---------

dir_scripts = "scripts"
dir_data = "../../data"
dir_data_cellranger_ref = dir_data + "/cellranger/refdata-gex-GRCh38-2020-A"
dir_genotype = "../../genotype"
dir_outputs = "../../workflow/outputs"
dir_outputs_HGSOC = dir_outputs + "/HGSOC"
dir_runtimes = "../../workflow/runtimes"
dir_runtimes_HGSOC = dir_runtimes + "/HGSOC"
dir_timestamps = "../../workflow/timestamps"
dir_timestamps_HGSOC = dir_timestamps + "/HGSOC"


sample_ids_HGSOC = ["16030X2_HJVMLDMXX", "16030X3_HJTWLDMXX", "16030X4_HJTWLDMXX"]
sample_ids_HGSOC_short = ["X2", "X3", "X4"]
sample_ids_HGSOC_short_named = {"16030X2_HJVMLDMXX": "X2", 
                                "16030X3_HJTWLDMXX": "X3", 
                                "16030X4_HJTWLDMXX": "X4"}

fastq_dirs_HGSOC = {"16030X2_HJVMLDMXX": "../../data/HGSOC/16030R/Fastq/16030X2_HJVMLDMXX", 
                    "16030X3_HJTWLDMXX": "../../data/HGSOC/16030R/Fastq/16030X3_HJTWLDMXX", 
                    "16030X4_HJTWLDMXX": "../../data/HGSOC/16030R/Fastq/16030X4_HJTWLDMXX"}


# ------------
# run workflow
# ------------

# command to run workflow on cluster
# notes:
# - using number of threads specified in each rule
# - using memory equal to "threads * mem_free" and "threads * h_vmem" (if more 
# precise control is required over the amount of memory for each job, this could 
# be specified in a Snakemake cluster config file)

# snakemake --cluster "qsub -V -cwd -pe local {threads} -l mem_free=5G,h_vmem=10G,h_fsize=300G" -j 3 --local-cores 30 --latency-wait 10


# --------------
# workflow rules
# --------------

# default rule

rule all:
  input:
    dir_timestamps + "/HGSOC/doublets_sims/20pc/vireo/timestamp_vireo_HGSOC_20pc.txt"


# ---------
# run Vireo
# ---------

# for one doublets simulation scenario (dataset, percentage of doublets)
# note parameter for number of samples (3 samples for HGSOC dataset)
rule run_vireo_HGSOC_20pc:
  input:
    dir_timestamps + "/HGSOC/doublets_sims/20pc/cellSNP/timestamp_cellSNP_HGSOC_20pc.txt", 
    script_vireo = dir_scripts + "/run_vireo.sh"
  output:
    dir_timestamps + "/HGSOC/doublets_sims/20pc/vireo/timestamp_vireo_HGSOC_20pc.txt"
  params:
    n_samples = 3, 
    dataset_name = "HGSOC", 
    prop_doublets = "20pc"
  threads: 1
  shell:
    "bash {input.script_vireo} {dir_runtimes} {dir_timestamps} {threads} "
    "{dir_outputs} {params.n_samples} "
    "{params.dataset_name} {params.prop_doublets}"


# -----------
# run cellSNP
# -----------

# for one doublets simulation scenario (dataset, percentage of doublets)
rule run_cellSNP_HGSOC_20pc:
  input:
    dir_timestamps + "/HGSOC/doublets_sims/20pc/parse_and_index_BAM_doublets/timestamp_parse_and_index_BAM_doublets_HGSOC_20pc.txt", 
    script_cellSNP = dir_scripts + "/run_cellSNP.sh"
  output:
    dir_timestamps + "/HGSOC/doublets_sims/20pc/cellSNP/timestamp_cellSNP_HGSOC_20pc.txt"
  params:
    dataset_name = "HGSOC", 
    prop_doublets = "20pc"
  threads: 10
  shell:
    "bash {input.script_cellSNP} {dir_runtimes} {dir_timestamps} {threads} "
    "{dir_outputs} {dir_genotype} "
    "{params.dataset_name} {params.prop_doublets}"


# ---------------------------------------------------------
# parse and index merged BAM files for doublets simulations
# ---------------------------------------------------------

# for one doublets simulation scenario (dataset, percentage of doublets)
rule parse_and_index_BAM_doublets_HGSOC_20pc:
  input:
    dir_timestamps + "/HGSOC/doublets_sims/20pc/lookup_table_doublets/timestamp_lookup_table_doublets_HGSOC_20pc.txt", 
    script_parse_and_index_BAM_doublets_HGSOC_20pc = dir_scripts + "/parse_and_index_BAM_doublets_HGSOC_20pc.sh"
  output:
    dir_timestamps + "/HGSOC/doublets_sims/20pc/parse_and_index_BAM_doublets/timestamp_parse_and_index_BAM_doublets_HGSOC_20pc.txt"
  params:
    dataset_name = "HGSOC", 
    prop_doublets = "20pc"
  threads: 1
  shell:
    "bash {input.script_parse_and_index_BAM_doublets_HGSOC_20pc} "
    "{dir_runtimes} {dir_timestamps} {threads} {dir_outputs} "
    "{params.dataset_name} {params.prop_doublets}"


# ---------------------------------------------------
# generate awk lookup tables for doublets simulations
# ---------------------------------------------------

# all datasets (extend inputs and outputs to add more datasets)
rule generate_awk_lookup_tables:
  input:
    dir_timestamps_HGSOC + "/parse_and_merge_barcodes/timestamp_parse_and_merge_barcodes.txt", 
    script_generate_awk_lookup_tables_doublets = dir_scripts + "/generate_awk_lookup_tables_doublets.R"
  output:
    dir_timestamps + "/HGSOC/doublets_sims/20pc/lookup_table_doublets/timestamp_lookup_table_doublets_HGSOC_20pc.txt"
  threads: 1
  shell:
    "Rscript {input.script_generate_awk_lookup_tables_doublets} "
    "{dir_runtimes} {dir_timestamps} {dir_outputs}"


# ----------------------------------
# parse and merge cell barcode files
# ----------------------------------

# HGSOC
rule parse_and_merge_barcodes_HGSOC:
  input:
    dir_timestamps_HGSOC + "/merge_and_index_BAM/timestamp_merge_and_index_BAM.txt", 
    script_parse_and_merge_barcodes = dir_scripts + "/parse_and_merge_barcodes_HGSOC.sh"
  output:
    dir_timestamps_HGSOC + "/parse_and_merge_barcodes/timestamp_parse_and_merge_barcodes.txt"
  params:
    sample_id_1 = lambda wildcards: sample_ids_HGSOC[0], 
    sample_id_2 = lambda wildcards: sample_ids_HGSOC[1], 
    sample_id_3 = lambda wildcards: sample_ids_HGSOC[2], 
    sample_id_1_short = lambda wildcards: sample_ids_HGSOC_short[0], 
    sample_id_2_short = lambda wildcards: sample_ids_HGSOC_short[1], 
    sample_id_3_short = lambda wildcards: sample_ids_HGSOC_short[2]
  threads: 1
  shell:
    "bash {input.script_parse_and_merge_barcodes} {dir_runtimes_HGSOC} {dir_timestamps_HGSOC} {threads} "
    "{dir_outputs_HGSOC} "
    "{params.sample_id_1} {params.sample_id_2} {params.sample_id_3} "
    "{params.sample_id_1_short} {params.sample_id_2_short} {params.sample_id_3_short}"


# -------------------------
# merge and index BAM files
# -------------------------

# HGSOC
rule merge_and_index_BAM_HGSOC:
  input:
    expand(dir_timestamps_HGSOC + "/parse_BAM_files/timestamp_parse_BAM_files_{sample_HGSOC}.txt", sample_HGSOC = sample_ids_HGSOC), 
    script_merge_and_index_BAM = dir_scripts + "/merge_and_index_BAM_HGSOC.sh"
  output:
    dir_timestamps_HGSOC + "/merge_and_index_BAM/timestamp_merge_and_index_BAM.txt"
  params:
    sample_id_1 = lambda wildcards: sample_ids_HGSOC[0], 
    sample_id_2 = lambda wildcards: sample_ids_HGSOC[1], 
    sample_id_3 = lambda wildcards: sample_ids_HGSOC[2]
  threads: 1
  shell:
    "bash {input.script_merge_and_index_BAM} {dir_runtimes_HGSOC} {dir_timestamps_HGSOC} {threads} "
    "{dir_outputs_HGSOC} {params.sample_id_1} {params.sample_id_2} {params.sample_id_3}"


# ---------------------------------------------------------
# parse BAM files to add unique sample IDs to cell barcodes
# ---------------------------------------------------------

# HGSOC
rule parse_BAM_files_HGSOC:
  input:
    dir_timestamps_HGSOC + "/cellranger/timestamp_cellranger_{sample_HGSOC}.txt", 
    script_parse_BAM_files = dir_scripts + "/parse_BAM_files.sh"
  output:
    dir_timestamps_HGSOC + "/parse_BAM_files/timestamp_parse_BAM_files_{sample_HGSOC}.txt"
  params:
    short_sample_id = lambda wildcards: sample_ids_HGSOC_short_named[wildcards.sample_HGSOC]
  threads: 1
  shell:
    "bash {input.script_parse_BAM_files} {dir_runtimes_HGSOC} {dir_timestamps_HGSOC} {threads} "
    "{wildcards.sample_HGSOC} {params.short_sample_id} {dir_outputs_HGSOC}"


# ---------------
# run Cell Ranger
# ---------------

# HGSOC
rule run_cellranger_HGSOC:
  input:
    script_cellranger = dir_scripts + "/run_cellranger.sh"
  output:
    dir_timestamps_HGSOC + "/cellranger/timestamp_cellranger_{sample_HGSOC}.txt"
  params:
    fastq_dir = lambda wildcards: fastq_dirs_HGSOC[wildcards.sample_HGSOC]
  threads: 10
  shell:
    "bash {input.script_cellranger} {dir_runtimes_HGSOC} {dir_timestamps_HGSOC} {threads} "
    "{wildcards.sample_HGSOC} {dir_data_cellranger_ref} "
    "{params.fastq_dir} {dir_outputs_HGSOC}"

